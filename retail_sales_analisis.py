# -*- coding: utf-8 -*-
"""Retail Sales Analisis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RqYjd8naHHXGy3oZ_xninTGDuw5Zt41K
"""

# Setup & Load Data

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# load
df = pd.read_csv("Dummy_Sales_TDN_2025.csv")

# cleaning
df["Order Date"] = pd.to_datetime(df["Order Date"])
df["Revenue"] = df["Net Value"]

df.head()

# 1. KPI Summary (Total Sales, Profit, Quantity)

total_sales = df["Revenue"].sum()
total_profit = df["Profit"].sum()
total_qty = df["Qty Sold"].sum()
profit_margin = total_profit / total_sales

print(f"Total Sales  : {total_sales:,.0f}")
print(f"Total Profit : {total_profit:,.0f}")
print(f"Total Qty    : {total_qty:,.0f}")
print(f"Margin       : {profit_margin:.2%}")

"""The business generated total revenue of Rp 87.8 million with a net profit of Rp 19.9 million, resulting in a healthy profit margin of 22.67%.
This indicates efficient cost control and strong pricing strategy.
On average, each product contributes approximately Rp 29.5k in revenue, suggesting a mid-priced retail segment with stable demand.
"""

# 2. Monthly Sales Trend

monthly = df.resample("M", on="Order Date")[["Revenue","Profit"]].sum()

monthly.plot(figsize=(10,5))
plt.title("Monthly Revenue vs Profit")
plt.show()

"""Sales performance shows clear seasonality with peak revenue occurring in May and a noticeable slowdown during Q3 (July‚ÄìOctober). Profit trends closely follow revenue, indicating stable margins and consistent cost control. This suggests that profitability is primarily driven by sales volume rather than cost fluctuations. Strategic promotions during low-demand months could help smooth revenue volatility.

**Bulan terbaik ‚Üí Mei**

- Revenue paling tinggi (~11.5M)
- Profit paling tinggi (~2.7M)
- Artinya: permintaan puncak terjadi di Mei.
- Kemungkinan karena promo, hari raya / event, stok lengkap.
- Action: ulangi strategi Mei (promo/kampanye/stok).

**Bulan terlemah ‚Üí Agustus-Oktober**

- Revenue turun drastis (~4.5-5M)
- Profit juga paling kecil (~1M)
- Artinya: low season / demand sedikit.
- Kemungkinan karena sepi event, daya beli turun, produk slow moving, stok kurang.
- Action: diskon, bundling, campaign marketing, clearance dead stock.
"""

# 3. Top Products (Best Seller Ranking)

top_products = (
    df
    .groupby("SKU Name")["Revenue"]
    .sum()
    .sort_values(ascending=False)
    .head(10)
)

top_products.plot(kind="barh", figsize=(8,5))
plt.gca().invert_yaxis()
plt.title("Top 10 Products by Revenue")
plt.show()

"""Revenue distribution is highly concentrated, with the top product contributing significantly more than others. This indicates a strong dependency on a few high-performing SKUs. Maintaining stock availability for these products is critical to sustain overall sales performance. Mid-tier products provide stable revenue streams, while lower-tier products should be monitored for inventory efficiency."""

# 4. Payment Method Distribution

payment = df.groupby("Payment Method")["Revenue"].sum()

payment.plot(kind="pie", autopct="%1.1f%%")
plt.ylabel("")
plt.title("Payment Method Share")
plt.show()

"""The majority of transactions (74%) are cashless, indicating strong adoption of digital payments. Debit cards dominate at 31.2%, suggesting higher-value purchases and stable customer spending behavior. Voucher usage is relatively high (24.7%), which may boost sales volume but requires monitoring to prevent margin erosion. QRIS adoption remains moderate and presents growth opportunities through targeted promotions."""

# 5. Inventory Analysis (Sales Velocity + ABC Classification)
# Sales Velocity (units per day)

days = (df["Order Date"].max() - df["Order Date"].min()).days

velocity = (
    df.groupby("SKU Name")["Qty Sold"]
    .sum()
    .div(days)
    .sort_values(ascending=False)
)

velocity.head()

"""**Insight penting**

Walaupun ini top velocity di dataset kamu, tapi angkanya kecil semua (< 0.05/hari)

Artinya: sebagian besar SKU jarang terjual

Kemungkinan karena terlalu banyak variasi produk, demand tersebar dan banyak slow stock
"""

# ABC Classification (Pareto 80/20)

product_sales = df.groupby("SKU Name")["Revenue"].sum().sort_values(ascending=False)

cum_pct = product_sales.cumsum() / product_sales.sum()

abc = pd.DataFrame({
    "Revenue": product_sales,
    "CumPct": cum_pct
})

def classify(x):
    if x <= 0.8:
        return "A"
    elif x <= 0.95:
        return "B"
    else:
        return "C"

abc["Class"] = abc["CumPct"].apply(classify)

abc.head()

"""Class A = top 80% revenue contributor

Jadi sedikit produk ‚Üí sebagian besar uang

Ini namanya: Pareto Principle (80/20 rule)

Sales velocity analysis shows that most products sell slowly on a daily basis, indicating a wide SKU variety with low turnover. However, ABC classification reveals that a small number of high-value items contribute disproportionately to revenue. This suggests the business should prioritize stock availability and procurement for Class A products while minimizing overstock risk for slow-moving SKUs.
"""

# 6. Store Performance

store_perf = df.groupby("Store")[["Revenue","Profit"]].sum()
store_perf["Margin"] = store_perf["Profit"] / store_perf["Revenue"]
store_perf.sort_values("Revenue", ascending=False)

"""Store performance analysis shows that KRANJI generates the highest revenue, indicating strong customer demand. However, KRANGGAN achieves the highest profit margin (28%), suggesting superior cost efficiency and product mix. Meanwhile, Jati Rawamangun records the lowest margin and may require operational improvements. Overall, profitability varies more due to efficiency rather than sales volume alone."""

# 7. Dead Stock Detection

dead_stock = pd.DataFrame({
    "Revenue": product_sales,
    "Velocity": velocity
}).fillna(0)

dead_stock = dead_stock.sort_values(["Revenue","Velocity"]).head(10)

dead_stock

"""Dead stock analysis reveals several SKUs with extremely low sales velocity and minimal revenue contribution. Some products sell less than once every 3‚Äì6 months, resulting in inefficient inventory holding and potential expiration risk. These items should be considered for stock reduction, discount clearance, or discontinuation to improve cash flow and warehouse efficiency."""

pip install statsmodels

# 8. Sales Forecasting (Simple ARIMA)

from statsmodels.tsa.arima.model import ARIMA

ts = df.resample("M", on="Order Date")["Revenue"].sum()

model = ARIMA(ts, order=(1,1,1))
fit = model.fit()

forecast = fit.forecast(steps=3)

print(forecast)

ts.plot(label="Actual")
forecast.plot(label="Forecast")
plt.legend()
plt.show()

# 9. Market Basket (Produk sering dibeli bersama)

from mlxtend.frequent_patterns import apriori, association_rules

basket = (
    df.groupby(["Order ID","SKU Name"])["Qty Sold"]
    .sum().unstack().fillna(0)
)

basket = basket.applymap(lambda x: 1 if x>0 else 0)

freq = apriori(basket, min_support=0.001, use_colnames=True)
rules = association_rules(freq, metric="lift", min_threshold=1)

rules.sort_values("lift", ascending=False).head()

"""Initial market basket analysis produced rules with very high confidence and lift but extremely low support. This indicates that the combinations occurred only in very few transactions and may not represent consistent customer behavior. Further filtering with higher support thresholds is required to identify meaningful bundling opportunities."""

pip install streamlit pandas matplotlib mlxtend statsmodels

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

st.set_page_config(page_title="Sales Dashboard", layout="wide")

# ==============================
# LOAD DATA
# ==============================
@st.cache_data
def load_data():
    df = pd.read_csv("Dummy_Sales_TDN_2025.csv")
    df["Order Date"] = pd.to_datetime(df["Order Date"])
    df["Revenue"] = df["Net Value"]
    return df

df = load_data()

# ==============================
# SIDEBAR FILTER
# ==============================
st.sidebar.title("Filters")

stores = st.sidebar.multiselect(
    "Store",
    options=df["Store"].unique(),
    default=df["Store"].unique()
)

categories = st.sidebar.multiselect(
    "Category",
    options=df["SKU Category"].unique(),
    default=df["SKU Category"].unique()
)

years = st.sidebar.multiselect(
    "Year",
    options=df["Order Date"].dt.year.unique(),
    default=df["Order Date"].dt.year.unique()
)

df = df[
    (df["Store"].isin(stores)) &
    (df["SKU Category"].isin(categories)) &
    (df["Order Date"].dt.year.isin(years))
]

# ==============================
# TITLE
# ==============================
st.title("üìä Sales Analytics Dashboard")

# ==============================
# KPI SECTION
# ==============================
total_sales = df["Revenue"].sum()
total_profit = df["Profit"].sum()
total_qty = df["Qty Sold"].sum()
margin = total_profit / total_sales

c1, c2, c3, c4 = st.columns(4)

c1.metric("Total Sales", f"{total_sales:,.0f}")
c2.metric("Total Profit", f"{total_profit:,.0f}")
c3.metric("Quantity Sold", f"{total_qty:,.0f}")
c4.metric("Profit Margin", f"{margin:.2%}")

st.divider()

# ==============================
# MONTHLY TREND
# ==============================
st.subheader("üìà Monthly Trend")

monthly = df.resample("M", on="Order Date")[["Revenue","Profit"]].sum()

fig, ax = plt.subplots()
ax.plot(monthly.index, monthly["Revenue"], label="Revenue")
ax.plot(monthly.index, monthly["Profit"], label="Profit")
ax.legend()

st.pyplot(fig)

# ==============================
# TOP PRODUCTS
# ==============================
st.subheader("üèÜ Top Products")

top_products = (
    df.groupby("SKU Name")["Revenue"]
    .sum()
    .sort_values(ascending=False)
    .head(10)
)

fig2, ax2 = plt.subplots()
ax2.barh(top_products.index, top_products.values)
ax2.invert_yaxis()

st.pyplot(fig2)

# ==============================
# PAYMENT METHOD
# ==============================
st.subheader("üí≥ Payment Method Distribution")

payment = df.groupby("Payment Method")["Revenue"].sum()

fig3, ax3 = plt.subplots()
ax3.pie(payment, labels=payment.index, autopct="%1.1f%%")

st.pyplot(fig3)

# ==============================
# INVENTORY ANALYSIS
# ==============================
st.subheader("üì¶ Inventory Analysis (ABC Classification)")

product_sales = (
    df.groupby("SKU Name")["Revenue"]
    .sum()
    .sort_values(ascending=False)
)

cum_pct = product_sales.cumsum() / product_sales.sum()

abc = pd.DataFrame({
    "Revenue": product_sales,
    "CumPct": cum_pct
})

def classify(x):
    if x <= 0.8:
        return "A"
    elif x <= 0.95:
        return "B"
    else:
        return "C"

abc["Class"] = abc["CumPct"].apply(classify)

st.dataframe(abc.head(20))

# ==============================
# DAILY SALES
# ==============================
st.subheader("üìÖ Daily Sales Pattern")

daily = df.resample("D", on="Order Date")["Revenue"].sum()

fig4, ax4 = plt.subplots()
ax4.plot(daily.index, daily.values)

st.pyplot(fig4)

# ==============================
# DEAD STOCK
# ==============================
st.subheader("‚ö†Ô∏è Dead Stock Detection")

days = (df["Order Date"].max() - df["Order Date"].min()).days

velocity = (
    df.groupby("SKU Name")["Qty Sold"]
    .sum()
    .div(days)
)

dead_stock = pd.DataFrame({
    "Revenue": product_sales,
    "Velocity": velocity
}).fillna(0)

dead_stock = dead_stock.sort_values(["Revenue","Velocity"]).head(10)

st.dataframe(dead_stock)

# ==============================
# FOOTER
# ==============================
st.caption("Built with using Streamlit & Python")

!streamlit run app.py